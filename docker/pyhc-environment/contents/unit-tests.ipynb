{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1b3102-f2dd-4c19-aeed-0f9c76ea150e",
   "metadata": {},
   "source": [
    "# PyHC Core Package Unit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c6889-91dc-45df-99da-2103eb6f98e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b0144-6595-4f5f-8502-f2783447db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import subprocess\n",
    "\n",
    "def clone_repo(repo_url: str, tag_or_branch: str, target_dir: str):\n",
    "    \"\"\"Clone a repository at a specific tag or branch into target_dir.\"\"\"\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    cmd = [\"git\", \"clone\", \"--branch\", tag_or_branch, repo_url, target_dir]\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "def run_pytest(test_args: str = \".\"):\n",
    "    \"\"\"\n",
    "    Run pytest with junitxml output and return True if the command runs.\n",
    "    test_args can be a directory, file pattern, or additional pytest flags.\n",
    "    \"\"\"\n",
    "    cmd = [\"pytest\", \"--junitxml=test-results.xml\"]\n",
    "    if isinstance(test_args, str):\n",
    "        cmd.extend(test_args.split())\n",
    "    else:\n",
    "        cmd.extend(test_args)\n",
    "    # Using subprocess.run here to avoid raising exception on test failure\n",
    "    subprocess.run(cmd, check=False)\n",
    "\n",
    "def parse_test_results(xml_path: str = \"test-results.xml\"):\n",
    "    \"\"\"Parse a JUnit XML results file and return total, passed, failed, etc.\"\"\"\n",
    "    if not os.path.isfile(xml_path):\n",
    "        # If no test results are produced, treat it as 0 tests run\n",
    "        return 0, 0, 0, 0, 0\n",
    "\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    total = errors = failures = skipped = 0\n",
    "    if root.tag == 'testsuites':\n",
    "        for testsuite in root.findall('testsuite'):\n",
    "            total += int(testsuite.attrib.get('tests', 0))\n",
    "            errors += int(testsuite.attrib.get('errors', 0))\n",
    "            failures += int(testsuite.attrib.get('failures', 0))\n",
    "            skipped += int(testsuite.attrib.get('skipped', 0))\n",
    "    elif root.tag == 'testsuite':\n",
    "        total = int(root.attrib.get('tests', 0))\n",
    "        errors = int(root.attrib.get('errors', 0))\n",
    "        failures = int(root.attrib.get('failures', 0))\n",
    "        skipped = int(root.attrib.get('skipped', 0))\n",
    "    else:\n",
    "        raise RuntimeError(f'Unexpected root tag in test-results.xml: {root.tag}')\n",
    "\n",
    "    passed = total - errors - failures\n",
    "    pass_rate = (passed / total) * 100 if total > 0 else 0\n",
    "    return total, passed, failures, errors, skipped, pass_rate\n",
    "\n",
    "def check_pass_rate(pass_rate: float, threshold: float, package_name: str):\n",
    "    \"\"\"Check if pass_rate meets the threshold, raise RuntimeError if not.\"\"\"\n",
    "    if pass_rate < threshold:\n",
    "        raise RuntimeError(f'{package_name} tests failed pass rate threshold ({threshold}%).')\n",
    "\n",
    "def print_test_summary(package_name: str, total: int, passed: int, failures: int, errors: int, skipped: int, pass_rate: float):\n",
    "    \"\"\"Print a summary of test results.\"\"\"\n",
    "    print(f'{package_name} Tests:')\n",
    "    print(f'Total tests: {total}')\n",
    "    print(f'Passed (including skipped): {passed}')\n",
    "    print(f'Failures: {failures}')\n",
    "    print(f'Errors: {errors}')\n",
    "    print(f'Skipped: {skipped}')\n",
    "    print(f'Pass rate: {pass_rate:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a5240-35c5-4321-9b36-0329c7c4b655",
   "metadata": {},
   "source": [
    "## 1. Test HAPI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1517e1c2-3537-463e-9b6f-82ac828388bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hapiclient\n",
    "\n",
    "hapiclient_version_tag = hapiclient.__version__.split('.dev')[0]\n",
    "\n",
    "# Clone repo\n",
    "clone_repo(\"https://github.com/hapi-server/client-python.git\", f\"v{hapiclient_version_tag}\", \"client-python\")\n",
    "\n",
    "# Run tests\n",
    "os.chdir(\"client-python\")\n",
    "run_pytest(\"hapiclient/test/\")\n",
    "total, passed, failures, errors, skipped, pass_rate = parse_test_results(\"test-results.xml\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "print_test_summary(\"HAPI Client\", total, passed, failures, errors, skipped, pass_rate)\n",
    "check_pass_rate(pass_rate, 85, \"HAPI Client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e27778-5187-4905-b561-cb5941d9154f",
   "metadata": {},
   "source": [
    "## 2. Test PlasmaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5f427f-62b2-4cba-9c2d-40e3ce7b8df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plasmapy\n",
    "\n",
    "plasmapy_version_tag = plasmapy.__version__.split('.dev')[0]\n",
    "\n",
    "# Clone repo\n",
    "clone_repo(\"https://github.com/PlasmaPy/PlasmaPy.git\", f\"v{plasmapy_version_tag}\", \"PlasmaPy\")\n",
    "\n",
    "# Run tests\n",
    "os.chdir(\"PlasmaPy\")\n",
    "run_pytest(\"--continue-on-collection-errors --ignore=tests/utils/data/test_downloader.py\")\n",
    "total, passed, failures, errors, skipped, pass_rate = parse_test_results(\"test-results.xml\")\n",
    "os.chdir(\"..\")\n",
    "\n",
    "print_test_summary(\"PlasmaPy\", total, passed, failures, errors, skipped, pass_rate)\n",
    "check_pass_rate(pass_rate, 100, \"PlasmaPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2e683-7248-431b-889a-4ae789ba5b10",
   "metadata": {},
   "source": [
    "## 3. Test pysat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b522bf93-dabe-4db8-a2a2-529bf0b4d11e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pysat\n",
    "import os\n",
    "\n",
    "# Ensure a data directory for pysat\n",
    "if not os.path.exists('pysatData'):\n",
    "    os.makedirs('pysatData')\n",
    "pysat.params['data_dirs'] = [os.path.abspath('pysatData')]\n",
    "\n",
    "# Run tests\n",
    "run_pytest(\"--pyargs pysat.tests\")\n",
    "total, passed, failures, errors, skipped, pass_rate = parse_test_results(\"test-results.xml\")\n",
    "\n",
    "print_test_summary(\"pysat\", total, passed, failures, errors, skipped, pass_rate)\n",
    "check_pass_rate(pass_rate, 98, \"pysat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8eac59-4edc-4398-822c-6412c1d2aa3f",
   "metadata": {},
   "source": [
    "## 4. Test PySPEDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de223c-28e2-42a4-8134-5df116ad277d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run tests\n",
    "!pip install obspy\n",
    "run_pytest(\"--pyargs pyspedas\")\n",
    "total, passed, failures, errors, skipped, pass_rate = parse_test_results(\"test-results.xml\")\n",
    "\n",
    "print_test_summary(\"pySPEDAS\", total, passed, failures, errors, skipped, pass_rate)\n",
    "check_pass_rate(pass_rate, 90, \"pySPEDAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde6bf6-58d3-4f93-83e6-eb69639a48a6",
   "metadata": {},
   "source": [
    "## 5. Test SpacePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992e68e-3e17-41d7-a874-4f34995c4198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacepy\n",
    "\n",
    "spacepy_version_tag = spacepy.__version__.split('.dev')[0]\n",
    "\n",
    "# Clean up if previous clone exists\n",
    "if os.path.exists('spacepy'):\n",
    "    shutil.rmtree('spacepy')\n",
    "\n",
    "!git clone --branch \"release-{spacepy_version_tag}\" \"https://github.com/spacepy/spacepy.git\"\n",
    "%cd spacepy/tests\n",
    "\n",
    "# Run selected test files\n",
    "!python test_ae9ap9.py\n",
    "!python test_coordinates.py\n",
    "!python test_ctrans.py\n",
    "!python test_datamanager.py\n",
    "!python test_datamodel.py\n",
    "!python test_empiricals.py\n",
    "!python test_igrf.py\n",
    "!python test_irbempy.py\n",
    "!python test_lanlstar.py\n",
    "!python test_lib.py\n",
    "!python test_omni.py\n",
    "!python test_plot.py\n",
    "!python test_plot_utils.py\n",
    "!python test_poppy.py\n",
    "!python test_pybats.py\n",
    "!python test_pycdf.py\n",
    "!python test_pycdf_istp.py\n",
    "!python test_rst.py\n",
    "!python test_seapy.py\n",
    "!python test_spectrogram.py\n",
    "!python test_testing.py\n",
    "!python test_time.py\n",
    "!python test_toolbox.py\n",
    "\n",
    "# SpacePy doesn't produce a single junit xml via these commands.\n",
    "# If you need pass/fail info, consider modifying tests or using pytest.\n",
    "# For now, just assume no major failures if return code is 0.\n",
    "\n",
    "print(\"SpacePy tests executed. Note: No automatic pass rate calculation done here.\")\n",
    "print(\"If you need pass/fail rate, you must run tests via pytest with --junitxml.\")\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07547ad-0789-4bc7-a485-71c3bb45f696",
   "metadata": {},
   "source": [
    "## 6. Test SunPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7861a-dc87-4f84-ad9c-d5c2e6cbaace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sunpy\n",
    "\n",
    "# Run tests\n",
    "run_pytest(\"--pyargs sunpy\")\n",
    "total, passed, failures, errors, skipped, pass_rate = parse_test_results(\"test-results.xml\")\n",
    "\n",
    "print_test_summary(\"SunPy\", total, passed, failures, errors, skipped, pass_rate)\n",
    "check_pass_rate(pass_rate, 100, \"SunPy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
